\section{Preliminaries}\label{sec:preliminaries}
In this section, we introduce the concepts and definitions essential for understanding the subsequent sections.
We begin by defining the key concepts of a \gls{hmm} and then describe how it can be represented using matrices.

We then introduce the Baum-Welch algorithm, which estimates the parameters of a \gls{hmm} from observed data.
We describe all the steps involved in the Baum-Welch algorithm, namely the forward-backward algorithm and the parameter's update.

Finally, we describe how the Baum-Welch algorithm can be implemented using matrix operations.

\subsection{Hidden Markov Models}\label{subsec:hmm}
%definition of HMM
Baum and Petrie introduced \glspl{hmm} in 1966~\cite{baum1966statistical}.
\glspl{hmm} are a class of probabilistic models widely used to describe sequences of observations dependent on some underlying hidden states.
These models consist of two main components: observations and hidden states.
The observations are the visible data emitted by the model, while the hidden states represent the underlying process that generates these observations.
\glspl{hmm} have applications in fields such as speech recognition~\cite{chavan2013overview}, bioinformatics~\cite{de2007hidden}, and natural language processing~\cite{murveit1990integrating}.
\gls{hmm} was chosen as the model of choice for this project due to its versatility and ability to model complex systems.

\begin{definition}[Hidden Markov Model]
    A Hidden Markov Model (HMM) is a tuple $\mathcal{M} = (S, \mathcal{L}, \mathscr{l}, \tau,  \pi)$, where:
    \begin{itemize}
        \item $S$ is a finite set of states.
        \item $\mathcal{L}$ is a finite set of labels.
        \item $\mathscr{l}: S \rightarrow D(\mathcal{L})$ is the emission function.
        \item $\tau: S \rightarrow D(S)$ is the transition function.
        \item $\pi \in D(S)$ is the initial distribution.
    \end{itemize}
\end{definition}

$D(X)$ denotes the set of discrete probability distributions over a finite set.
The model emits a label $l \in \mathcal{L}$ in state $s \in S$ with probability $\mathscr{l}(s)(l)$, and transitions from state $s$ to state $s'$ with probability $\tau(s)(s')$, and starts in state $s$ with probability $\pi(s)$.

\subsection{Matrix Representation of HMMs}\label{subsec:matrix-representation}
\glspl{hmm} can be represented using various matrices.
The emission function $\mathscr{l}$ can be represented as a matrix $\pmb{\omega}$ where $\pmb{\omega}_{s, l} = \mathscr{l}(s)(l)$.
The matrix $\pmb{\omega}$ has the size $|S| \times |\mathcal{L}|$.
The sum of each row in the matrix $\pmb{\omega}$ is equal to one, reflecting the total probability of emitting all labels from a given state.


\[
    \pmb{\omega} = \begin{bmatrix}
                 \mathscr{l}(s_1)(l_1)     & \cdots & \mathscr{l}(s_1)(l_{|\mathcal{L}|})     \\
                 \vdots                    & \ddots & \vdots                                  \\
                 \mathscr{l}(s_{|S|})(l_1) & \cdots & \mathscr{l}(s_{|S|})(l_{|\mathcal{L}|})
    \end{bmatrix}
\]


The transition function $\tau$ can be represented as a stochastic matrix $\pmb{P}$ where $\pmb{P}_{s, s'} = \tau(s)(s')$.
The matrix $\pmb{P}$ has the size $|S| \times |S|$.
The sum of each row in $\pmb{P}$ is equal to one, reflecting the total probability of transitioning from a given state to all other states.

\[
    \pmb{P} = \begin{bmatrix}
            \tau(s_1)(s_1)     & \cdots & \tau(s_1)(s_{|S|})     \\
            \vdots             & \ddots & \vdots                 \\
            \tau(s_{|S|})(s_1) & \cdots & \tau(s_{|S|})(s_{|S|})
    \end{bmatrix}
\]

The initial distribution $\pi$ can be represented as a vector $\pmb{\pi}$ where $\pmb{\pi}_s = \pi(s)$.
The vector $\pmb{\pi}$ has the size $|S|$.
The sum of all elements in $\pmb{\pi}$ is equal to one, reflecting the fact that $\pi \in D(s)$.

\[
    \pmb{\pi} = \begin{bmatrix}
              \pi(s_1) \\
              \vdots   \\
              \pi(s_{|S|})
    \end{bmatrix}
\]

\subsection{Observations and Hidden States}\label{subsec:observations-hidden-states}
A \gls{hmm} can be understood as a stochastic generator of sequences of hidden states, referred to as a run. 
Formally, an infinite run is denoted as $\rho = s_1, s_2, \cdots s_n \cdots \in S^{\omega}$, where $S$ is the set of hidden states. 
The probability that the \gls{hmm}, denoted as $M$, generates a finite prefix of the run $\rho_n = s_1, s_2, \cdots s_n$ is given by:
\begin{equation}
    P(\rho_n) = \pi(s_1) \prod_{i = 1}^{n-1} \tau(s_i)(s_{i+1})
\end{equation}

Where $\pi(s_1)$ is the initial probability of state $s_1$, and $\tau(s_i)(s_{i+1})$ represents the transition probability from state $s_i$ to state $s_{i+1}$.

Although the run $\rho$ is not directly observable, it emits a corresponding sequence of observable labels, forming an observation trace $O = l_1, l_2, \cdots l_n \cdots \in L^{\omega}$, where $L$ is the set of observable labels.

The probability that the hidden state sequence $\rho_n = s_1, s_2, \cdots s_n$ produces the observed trace $O_n = l_1, l_2, \cdots l_n$ is given by:
\begin{equation}
    P(O_n | \rho_n) = P(\rho_n) \cdot \prod_{i = 1}^{n} \ell(s_i)(l_i)
\end{equation}

Where $\ell(s_i)(l_i)$ is the emission probability of label $l_i$ from state $s_i$.

In practical applications, rather than working with infinite sequences, we typically observe a multiset of finite observation sequences, denoted as $\mathcal{O} = \{O_1, O_2, \ldots, O_N\}$, where each $O_i$ is an observation sequence of labels $\mathbf{o} = o_0, o_1, \cdots, o_{|\mathbf{O}|-1}$.

These observed sequences serve as the input for parameter estimation in the \gls{hmm}, which involves determining the emission function $\ell$, the transition function $\tau$, and the initial distribution $\pi$ using algorithms like the Baum-Welch algorithm.

%An \gls{hmm} gives rise to observations, based its execution.
%A multiset of observations, denoted as  $\mathcal{O} = {O_1, O_2, \ldots, O_N}$, where each $O_i$ is an observation sequence of labels $\mathbf{O} = o_1, o_2, \ldots, o_{|\mathbf{O}|-1}$, can be used to estimate the parameters of the \gls{hmm} using the \gls{bw} algorithm.

%By parameters of the \gls{hmm} is meant the emission function, transition function, and initial distribution.

\subsection{The Baum-Welch Algorithm}\label{subsec:baum-welch}
The Baum-Welch algorithm is a fundamental method for estimating the parameters of a \gls{hmm} given a sequence of observations.
These parameters include the emission matrix $\pmb{\omega}$, the transition matrix $\pmb{P}$, and the initial state distribution $\pmb{\pi}$.
The algorithm is widely recognized as the standard approach for training \glspl{hmm} and was chosen for this project because it can estimate these parameters without prior knowledge of the hidden states that generated the observations~\cite{levinson1983introduction}.

The Baum-Welch algorithm applies the Expectation-Maximization (EM) framework to iteratively improve the likelihood of the observed data under the current model parameters. It does so untill it reaches a set convergence value, which indicates how much the model improves after each iteration.
It consists of the following steps:

\begin{enumerate}
    \item \textbf{Initialization:} Begin with a given initial estimates for the \gls{hmm} parameters $(\pmb{\pi}, \pmb{P}, \pmb{\omega})$.
    \item \textbf{Expectation Step (E-step):} Compute the expected counts of the latent variables, i.e., the hidden states, based on the observation sequence and the current model parameters.
    That is we compute the probabilities of observing the sequence up to time $t$, given that the \gls{hmm} is in state $s$ at time $t$ and the probabilities of observing the sequence from time $t+1$ to the end, given that the \gls{hmm} is in state $s$ at time $t$.
    \item \textbf{Maximization Step (M-step):} Update the \gls{hmm} parameters $(\pmb{\pi}, \pmb{P}, \pmb{\omega})$ to maximize the likelihood of the observed data based on the expected counts computed in the E-step.
    \item \textbf{Iteration:} Repeat the E-step and M-step until convergence, i.e., when the change in likelihood between iterations falls below a predefined threshold.
\end{enumerate}

The Baum Welch algorithm seeks to estimate the parameters $\pmb{\tau}$, $\pmb{\pi}$, and $\pmb{\omega}$ of a \gls{hmm} model $\mathcal{M}$, so that it maximizes the likelihood function $\mathfrak{l}(\mathcal{M} | O)$.
That is, the probability that the \gls{hmm} $\mathcal{M}$ has independently generated each observation sequence $O_1, \cdots, O_N$.

Starting with an initial hypothesis $\textbf{x}_0 = (\pmb{\pi}, \pmb{P}, \pmb{\omega})$, the algorithm produces a sequence of parameter estimates $\textbf{x}_1, \textbf{x}_2, \cdots$, where each new estimate improves upon the previous one.
The process terminates when the improvement in likelihood is sufficiently small, satisfying the convergence criterion:

\[
    ||\mathfrak{l}(x_n, o)|| < \epsilon
\]

Where $\mathfrak{l}(x_n, o)$ is the likelihood of all the observations under the parameters $x_n$, and $\epsilon > 0$ is a small threshold.
%where $l(\textbf{x}_n)$ is the likelihood of the observations under the parameters $\textbf{x}_n$, and $\epsilon > 0$ is a small threshold.

The steps of the Baum-Welch algorithm are detailed in the following sections, including the initialization of the \gls{hmm} parameters, the forward-backward algorithm, and the update step, see \autoref{subsec:initialization},~\ref{subsec:forward-backwards_algorithm}, and~\ref{subsec:update-algorithm} respectively.

\subsection{Initialization of HMM Parameters}\label{subsec:initialization}
Before starting the Baum-Welch algorithm, we need to initialize the model parameters: the emission matrix $\pmb{\omega}$, the transition matrix $\pmb{P}$, and the initial state distribution $\pmb{\pi}$.

Since the algorithm is designed to converge iteratively towards a locally optimal parameter set, the initial estimates do not need to be exact.
However, reasonable initialization can accelerate convergence and improve numerical stability~\cite{benyacoub2015initial}.

As we work with models that we have no prior knowledge of, meaning we do not know the number of observations or what states generated the observations, we cannot initialize the model parameters based on domain knowledge.
Therefore, we need to initialize the parameters based on some strategy.
If we set a probability to zero, we see in parameter estimation (\autoref{eq:xi}) that the probability will remain zero. 
Therefore if no domain knowledge is available, it is better to initialize the parameters with non-zero values.
A common approach to initialize these parameters is as one of the following strategies:

\begin{enumerate}
    \item Random initialization: 
    \begin{itemize}
        \item Assign random probabilities to for the initial state distribution $\pi_s$, such that $\sum_{s \in S} \pi_s = 1$.
        \item Assign random probabilities to each transition $P_{s, s'}$, such that $\sum_{s' \in S} P_{s, s'} = 1$.
        \item Assign random probabilities to each emission $\omega_{s, l}$, such that $\sum_{l \in \mathcal{L}} \omega_{s, l} = 1$ for all $s \in S$.
    \end{itemize}
    \item Uniform initialization: 
    \begin{itemize}
        \item Set $\pi_s = \frac{1}{|S|}$ for all $s \in S$.
        \item Set $P_{s, s'} = \frac{1}{|S|}$ for all $s, s' \in S$.
        \item Set $\omega_{s, l} = \frac{1}{|\mathcal{L}|}$ for all $s \in S, l \in \mathcal{L}$.
    \end{itemize}
\end{enumerate}

We initialize the parameters using random initialization, as it provides a diverse set of initial values that can help avoid local optima.
The uniform initialization is the worst choice as it provides the least amount of information. 
With uniform initialization, any transition is equally likely to be chosen to explain an observation, making the latent states indistinguishable from each other. 
Therefore it is not recommended for practical use.

These initialization strategies provide a starting point for the Baum-Welch algorithm, which iteratively refines the model parameters based on the observed data.

\subsection{Forward-Backward Algorithm}\label{subsec:forward-backwards_algorithm}
%Forward-Backward algorithm
For a given \gls{hmm} $\mathcal{M}$, the forward-backward algorithm computes the forward and backward variables, $\alpha_s(t)$ and $\beta_s(t)$, for each observation sequence $o_0, o_1, \cdots, o_{|\mathbf{o}|-1} = \mathbf{o} \in \mathcal{O}$.
The forward variable $\alpha_s(t)$ represents the likelihood of observing the partial sequence $o_0, o_1, \cdots, o_t$ and being in state $s$ at time $t$, given the model $\mathcal{M}$.
The backward variable $\beta_s(t)$ represents the likelihood of observing the partial sequence $o_{t+1}, o_{t+2}, \cdots, o_{|\mathbf{o}|-1}$ given state $s$ at time $t$ and the model $\mathcal{M}$.

The forward variable $\alpha_s(t)$ and backward variable $\beta_s(t)$ can be computed recursively as follows:

\begin{equation}
    \alpha_s(t) =
    \begin{cases}
        \pmb{\omega}_{s, o_t} \pmb{\pi}_s & \text{if } t = 0 \\
        \pmb{\omega}_{s, o_t} \sum_{s' \in S} \pmb{P}_{s's}\alpha_{s'}(t - 1) & \text{if } 0 < t \leq |\mathbf{o}| - 1 \\
    \end{cases}
    \label{eq:forward-recursive}
\end{equation}


\begin{equation}
    \beta_s(t) =
    \begin{cases}
        \mathbbm{1} & \text{if } t = |\mathbf{o}| - 1 \\
        \sum_{s' \in S} \pmb{P}_{ss'} \pmb{\omega}_{s'}(t + 1) \beta_{s'}(t + 1) & \text{if } 0 \leq t < |\mathbf{o}| - 1 \\
    \end{cases}
    \label{eq:backward-recursive}
\end{equation}


Here, $\pmb{\omega}_{s, o_t}$ is the likelihood of observing $o_t$ while being in state $s$ at time $t$ given the model $\mathcal{M}$.
Formally $\pmb{\omega}_{s, o_t} = \mathfrak{l}(o_t \mid s, \mathcal{M}) = \mathscr{l}(s)(o_t)$.

The forward-backward algorithm computes the forward and backward variables for each state $s$ and time $t$ in the observation sequence $\mathbf{o}$, providing a comprehensive view of the likelihood of the observed data under the model.

In preparation for later discussions, we would like to draw attention to the fact that the above recurrences can be solved using dynamic programming requiring one to use $\Theta(|S|\times|(|\mathbf{o}|-1)|)$ space.

\subsection{Update Step}\label{subsec:update-algorithm}
%Update of HMM
The update step refines the parameter values of the \gls{hmm} model based on the observed data and the forward and backward variables computed in the forward-backward algorithm.
Given the forward and backward variables $\alpha_s(t)$ and $\beta_s(t)$, the update step aims to maximize the likelihood of the observed data by adjusting the parameter values.

The update step iteratively refines the parameter values until convergence is reached.

\subsubsection{Intermediate Variables}
We need to calculate the intermediate variables $\gamma_s(t)$ and $\xi_{ss'}(t)$.
$\gamma_s(t)$ represents the expected number of times the model is in state $s$ at time $t$ given that the sequence $\mathbf{o}$ was observed.
$\xi_{ss'}(t)$ represents the expected number of transitions from state $s$ to state $s'$ at time $t$ given that the sequence $\mathbf{o}$ was observed.

For a given \gls{hmm} $\mathcal{M}$, the intermediate variables, $\gamma_s(t)$ and $\xi_{ss'}(t)$, are computed for each observation sequence $o_0, o_1, \dots, o_{|\mathbf{o}|-1} = \mathbf{o} \in \mathcal{O}$.
These variables are computed as follows:

\begin{equation}
    \gamma_s(t) = \frac{\alpha_s(t) \beta_s(t)}{\sum_{s' \in S} \;\alpha_{s'}(t) \beta_{s'}(t)}
    \label{eq:gamma}
\end{equation}

In \autoref{eq:gamma}, the numerator is the product of the forward variable $\alpha_s(t)$ and the backward variable $\beta_s(t)$, representing the joint probability of observing the entire sequence given that the model passed by state $s$ at time $t$.
The denominator represents the probability of the observation sequence.

\begin{equation}
    \xi_{ss'}(t) = \frac{\alpha_s(t) \pmb{P}_{ss'} \pmb{\omega}_{s'}(t + 1) \beta_{s'}(t + 1)}
    {\sum_{s''}\alpha_{s''}(t) \beta_{s''}(t)}
    %{\sum_{s'' \in S} \;(\sum_{s''' \in S} \; (\alpha_{s''}(t) \; P_{s''s'''} \; \omega_{s'''}(t + 1) \; \beta_{s'''}(t + 1)))}
    \label{eq:xi}
\end{equation}


In \autoref{eq:xi}, the numerator is the joint probability of observing the sequence given that the model transitions from state $s$ to state $s'$ at time $t$.
The denominator represents the probability of the observation sequence.

The terms $\gamma_s(t)$ and $\xi_{ss'}(t)$ are normalized to ensure they represent probabilities.
For $\gamma_s(t)$, this involves dividing by the total probability across all states at time $t$, while for $\xi_{ss'}(t)$, normalization occurs over all possible transitions at time $t$.

\subsubsection{Parameter Update}
The parameter update step refines the parameter values of the model based on the earlier computed intermediate variables $\gamma_s(t)$ and $\xi_{ss'}(t)$.
The update step aims to maximize the expected likelihood of the observed data given the model $\mathcal{M}$ by adjusting the parameter values.

Once $\gamma_s(t)$ and $\xi_{ss'}(t)$ are computed for all states $s, s'$ and all time steps $t$ for every observation sequence, the model parameters can be updated to maximize the expected log-likelihood.

\paragraph*{\textit{Transition Probabilities ($\pmb{P}$)}}

We update the transition probabilities based on the expected number of transitions between states:


\begin{equation}
    \pmb{P}_{s s'} = \frac{\sum_{t = 1}^{|\mathbf{o}|-1} \xi_{ss'}(t)}{\sum_{t = 1}^{|\mathbf{o}|-1} \gamma_s(t)}
    \label{eq:transition-probabilities}
\end{equation}


The numerator sums the expected number of transitions from state $s$ to state $s'$ over all time steps.
The denominator sums the expected number of times the model is in state $s$ over all time steps, ensuring $P_{ss'}$ is normalized across all $s'$.

\paragraph*{\textit{Emission Probabilities ($\pmb{\omega}$)}}

We update the emission probabilities based on the expected emissions of state $s$ and the corresponding observations, meaning the probability of observing the specific label $o$ in state $s$.
This is given by:

\begin{equation}
    \pmb{\omega}_{s, l} = \frac{\sum_{t = 1}^{|\mathbf{o}|-1} \gamma_s(t) \lBrack o_t = l \rBrack}{\sum_{t = 1}^{|\mathbf{o}|-1} \gamma_s(t)}
    \label{eq:omega}
\end{equation}

$\lBrack o_t = l \rBrack$ is an indicator function that returns 1 if the observation at time $t$ is label $l$ and 0 otherwise.
The numerator sums $\gamma_s(t)$ for all time steps $t$ where the observed value $o_t = l$., meaning the model is in state $s$ and emits the label $l$.

The denominator sums $\gamma_s(t)$ for all time steps $t$ where the model is in a given state $s$.


\paragraph*{\textit{Initial Probabilities ($\pmb{\pi}$)}}

We update the initial probabilities based on the expected number of times we start in state $s$.
\begin{equation}
    \pi_s = \gamma_s(1)
    \label{eq:initial-probabilities}
\end{equation}

We can then update the parameters $(\pmb{\pi}, \pmb{P}, \pmb{\omega})$ given the model $\mathcal{M}$ by maximizing the expected log-likelihood of the observed data under the model.
The update step iteratively refines the parameter values until convergence is reached.

\subsection{Matrix Operations}\label{subsec:matrix-operations}
%Baum-Welch with matrix operations
The Baum-Welch algorithm can be implemented using matrix operations to efficiently compute the forward and backward variables, intermediate variables, and parameter updates.

Given a \gls{hmm} $\mathcal{M}$ with parameters $\pmb{\omega}$, $\pmb{P}$ and $\pmb{\pi}$, and an observation sequence $\mathbf{o}$, the forward and backward variables $\pmb{\alpha}_t$ and $\pmb{\beta}_t$ can be computed using matrix operations as follows:

\begin{equation}
    \label{eq:alpha}
    \pmb{\alpha}_t =
    \begin{cases}
        \pmb{\omega}_0 \; \circ \; \pmb{\pi}   & \text{if } t = 0    \\
        \pmb{\omega}_t \; \circ \; \left( \pmb{P}^\top \pmb{\alpha}_{t - 1} \right)   & \text{if } 0 < t \leq |\mathbf{o}|-1 \\
    \end{cases}
\end{equation}


\begin{equation}
    \label{eq:beta}
    \pmb{\beta}_t =
    \begin{cases}
        \mathbbm{1} & \text{if } t = |\mathbf{o}|-1        \\
        \pmb{P} \; (\pmb{\beta}_{t + 1} \; \circ \; \pmb{\omega}_{t + 1}) & \text{if } 0 \leq t < |\mathbf{o}|-1 \\
    \end{cases}
\end{equation}

Here $\circ$ represents the Hadamard (point-wise) matrix multiplication, $\pmb{P}^\top$ denotes the transpose of the matrix $\pmb{P}$, and $\mathbbm{1}$ is a column vector of ones, and $\pmb{\omega}_t$ is the column vector that represents the label we are observing at time $t$ of matrix $\pmb{\omega}$.
The resulting vectors $\pmb{\alpha}_t$ and $\pmb{\beta}_t$ for each time step $t$ are then related to $\alpha_s(t)$ and $\beta_s(t)$ for some $s$ by:

\begin{align}
\pmb{\alpha}
    _t = \begin{bmatrix}
             \alpha_{s_0}(t)       \\
             \vdots                \\
             \alpha_{s_{|S|-1}}(t) \\
    \end{bmatrix}, \;
    \pmb{\beta}_t = \begin{bmatrix}
                    \beta_{s_0}(t)       \\
                    \vdots               \\
                    \beta_{s_{|S|-1}}(t) \\
    \end{bmatrix}
\end{align}

We denote $\pmb{\alpha}$ and $\pmb{\beta}$, as the matrices gathering the 
columns $\alpha_t$ and $\beta_t$ for $t = 1\cdots |\mathbf{o}|-1$

\begin{equation}
    \pmb{\alpha} = 
        \begin{bmatrix}
            \alpha_{s_0 t_{0}}  & \cdots & \alpha_{s_{|S|-1}t_{|\textbf{o}|-1}} \\
            \vdots               & \ddots & \vdots                      \\
            \alpha_{s_0 t_{0}}  & \cdots & \alpha_{s_{|S|-1}t_{|\textbf{o}|-1}}
        \end{bmatrix}
        \text{ and }
    \pmb{\beta} = 
        \begin{bmatrix}
            \beta_{s_0 t_{0}}  & \cdots & \beta_{s_{|S|-1}t_{|\textbf{o}|-1}} \\
            \vdots               & \ddots & \vdots                      \\
            \beta_{s_0 t_{0}}  & \cdots & \beta_{s_{|S|-1}t_{|\textbf{o}|-1}}
        \end{bmatrix}\label{eq:forward-backward-matrix}
\end{equation}

$\gamma$ and $\xi$ can be expressed in terms of matrix operations as follows:

\begin{equation}
\pmb{\gamma}
    _t = (\sum_{i=1}^{|\mathbf{o}|-1} (\pmb{\alpha}_{t i} \;\pmb{\beta}_{t i}))^{-1} \cdot \pmb{\alpha}_t \; \circ \; \pmb{\beta}_t
    \label{eq:gamma-matrix}
\end{equation}

\begin{equation}
\pmb{\xi}
    _t = ((\sum_{i=1}^{|\mathbf{o}|-1} (\pmb{\alpha}_{t i} \; \pmb{\beta}_{t i}))^{-1} \cdot \; \pmb{P}) \; \circ \;(\pmb{\alpha}_t \otimes (\pmb{\beta}_{t+1} \; \circ \; \pmb{\omega}_{t+1}))
    \label{eq:xi-matrix}
\end{equation}

Here $\otimes$ represents the Kronecker (block) matrix multiplication, $\cdot$ denotes the scalar product, and $^{-1}$ denotes the elementwise inverse of a matrix.

We can simplify $\sum_{i=1}^{|\mathbf{o}|-1} (\pmb{\alpha}_{t i} \pmb{\beta}_{t i})$ as, the sum does not depend on $t$:

\begin{align}
    \sum_{i=1}^{|\mathbf{o}|-1} (\pmb{\alpha}_{t i} \; \pmb{\beta}_{t i}) &= \sum_{i=1}^{|\mathbf{o}|-1} \pmb{\alpha}_{|\mathbf{o}|-1 i} \\
    &= \mathbbm{1}^T \; \pmb{\alpha}_{|\mathbf{o}|-1}
\end{align}

Here $\mathbbm{1}^T$ is a row vector of ones, and $\pmb{\alpha}_{|\mathbf{o}|-1}$ is the last column of the matrix $\pmb{\alpha}$.
From this we get:

\begin{equation}
\pmb{\gamma}
    _t = (\mathbbm{1}^T \; \pmb{\alpha}_{|\mathbf{o}|-1})^{-1} \cdot \pmb{\alpha}_t \; \circ \; \pmb{\beta}_t
    \label{eq:gamma-matrix-ones}
\end{equation}

\begin{equation}
\pmb{\xi}
    _t = ((\mathbbm{1}^T \; \pmb{\alpha}_{|\mathbf{o}|-1})^{-1} \cdot \; \pmb{P}) \; \circ \;(\pmb{\alpha}_t \otimes (\pmb{\beta}_{t+1} \; \circ \; \pmb{\omega}_{t+1}))
    \label{eq:xi-matrix-ones}
\end{equation}

The resulting vectors $\pmb{\gamma}_t$ and $\pmb{\xi}_t$ for each time step $t$ are then related to $\gamma_s(t)$ and $\xi_{ss'}(t)$ for some $s, s'$ by:

\begin{align}
\pmb{\gamma}_t = 
    \begin{bmatrix}
        \gamma_{s_0}(t)       \\
        \vdots                \\
        \gamma_{s_{|S|-1}}(t) \\
    \end{bmatrix}, \;
\pmb{\xi}_t = 
    \begin{bmatrix}
        \xi_{s_0 s_0}(t)      & \cdots & \xi_{s_0 s_{|S|-1}}(t)      \\
        \vdots                & \ddots & \vdots                      \\
        \xi_{s_{|S|-1}s_0}(t) & \cdots & \xi_{s_{|S|-1}s_{|S|-1}}(t) \\
    \end{bmatrix}
\end{align}

We can then update the parameters with matrix operations as follows:

\begin{equation}
\pmb{P}
    = (\mathbbm{1} \oslash \pmb{\gamma}) \bullet \pmb{\xi}
    \label{eq:transition-probabilities-update}
\end{equation}

\begin{equation}
\pmb{\omega}
    _s(o) = (\mathbbm{1} \oslash \pmb{\gamma}) \bullet (\sum_{t=1}^{|\mathbf{o}|-1} \pmb{\gamma}_t \otimes \mathbbm{1}_{yt}^{|\mathbf{o}|-1})
    \label{eq:omega-update}
\end{equation}

\begin{equation}
\pmb{\pi}
    = \pmb{\gamma}_1
    \label{eq:initial-probabilities-update}
\end{equation}

Here $\oslash$ denotes Hadamard division (elementwise division) and $\bullet$ denotes the Katri-Rao product (column-wise Kronecker product).
In the formulas above, $\mathbbm{1}$ denotes a column vector of ones, $\mathbbm{1}_{yt}$ denotes a column vector with $|\mathcal{L}|$ rows, with all elements set to zero except for the element at the index where $o_t = l$ which is set to one.

$\gamma$ and $\xi$ are the sum of the respective vectors over all time steps $t$:
\begin{align}
    \pmb{\gamma} = \sum_{t=1}^{|\mathbf{o}|-1} \pmb{\gamma}_t 
    \text{ and } 
    \pmb{\xi} = \sum_{t=1}^{|\mathbf{o}|-1} \pmb{\xi}_t
\end{align} 


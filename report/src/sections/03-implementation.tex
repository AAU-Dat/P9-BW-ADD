\section{Implementation}\label{sec:implementation}
In this section, we will discuss the implementation of the project.
We will start by discussing the tools used in the implementation, followed by the transition from matrices to \glspl{add}.
Finally, we will discuss the implementation of the matrix operations using \glspl{add}.

\subsection{CUDD}\label{subsec:cudd}
The Colorado University Decision Diagram (CUDD) library~\cite{somenzi1997cudd} is a powerful tool for implementing and manipulating decision diagrams, including \glspl{bdd} and \glspl{add}. \glspl{add} are compact representations of functions, often used to handle large state spaces symbolically and efficiently.

In this project, the CUDD library stores \glspl{add} and performs operations on them.
Its optimized algorithms and efficient memory management allow us to handle large and complex matrices symbolically, leading to significant performance improvements over traditional methods.

The CUDD library is implemented in C, ensuring high-performance execution, but it also ensures it can be used in C++ programs.

\subsection{Storm}\label{subsec:storm}
Storm is a versatile, open-source probabilistic model checking tool designed to verify the correctness and properties of stochastic models~\cite{hensel2021probabilistic}. It supports a wide range of probabilistic models, including \glspl{hmm},\glspl{mc} and \glspl{mdp}. Storm allows users to analyze models efficiently by computing various quantitative properties, such as probabilities, expected rewards, or long-run averages.

A key feature of Storm is its ability to represent models symbolically, leveraging data structures like \glspl{bdd} and \glspl{add}. These symbolic representations compactly encode the model's state space and transition structure, enabling efficient manipulation and analysis even for large-scale systems. Storm achieves this by interfacing with the CUDD library, mentioned earlier.

In our implementation, Storm serves as a parser for loading the input models. Specifically, we utilize Storm to convert the model into its \gls{add} representation. This \gls{add} representation provides a compact and hierarchical encoding of the underlying matrices, which can then be used to perform symbolic matrix operations using the CUDD library.

The reason for using Storm lies in it is open-source, which makes it easy to integrate into our project. Storm is designed to handle large and complex models efficiently for model checking.
Therefore the next step in Storm is to calculate the parameters of interest, such as transition probabilities, rewards, or other metrics derived from the model. By performing these computations symbolically within the ADD framework, we achieve a scalable and efficient approach to analyzing stochastic models.

\subsection{Transition to ADDs}\label{subsec:transition-to-adds}
The first step in the implementation is to transition from vectors and matrices to \glspl{add}.
This conversion leverages the compact and efficient representation of \glspl{add} to perform operations symbolically.

To convert a vector into an \gls{add}, the vector must first be interpreted as a square matrix.
This step ensures compatibility with the \gls{add} representation, which organizes data hierarchically.
When a matrix is represented as an \gls{add}, the matrix also has to be square, as the \gls{add} representation requires a square matrix, if the matrix is not square, it has to be padded with zeros to make it square.

Consider the following vector:

\[
    V=
    \begin{bmatrix}
        1 & 2 & 3 & 4 \\
    \end{bmatrix}
\]

This vector corresponds to a matrix of size $4 \times 4$.

\[
    \begin{bmatrix}
        1 & 2 & 3 & 4 \\
        0 & 0 & 0 & 0 \\
        0 & 0 & 0 & 0 \\
        0 & 0 & 0 & 0 \\
    \end{bmatrix}
\]
In an ADD, each layer corresponds to one binary variable (or bit) in the encoding of an index. 
For a matrix of size $n \times n$, where $n = 2^k$, the binary representation of the row and column indices requires $k$ bits each. 
By interleaving these bits (e.g., alternating between row and column bits), we construct a balanced and regular structure that preserves the matrix's two-dimensional nature.
In the case of the vector V, the vector has 4 elements, so it requires $4 = 2^2$ bits to represent the indices.

The binary representation of the vector entries is shown in \autoref{tab:vector}, the rest of the matrix indices is filled with zeros.

\begin{table}
    \centering
    \caption{Binary encoding of a vector V of size 4}
    \label{tab:vector}
    \begin{tabular}{lll}
        \toprule
        Vector Index & Value & Binary Encoding \\
        \midrule
        1            & 1     & 0000            \\
        2            & 2     & 0001            \\
        3            & 3     & 0010            \\
        4            & 4     & 0011            \\
        \bottomrule
    \end{tabular}
\end{table}

The \gls{add} representation of this vector is shown in \autoref{fig:add}.
The binary encodings determine the structure of the decision diagram, where each entry in the vector is stored as a terminal node.
The paths to these nodes are dictated by the binary representation of their indices.

\begin{figure*}
    \centering
    \input{figures/vector_add_example}
    \caption{Vector V represented as an ADD}
    \label{fig:add}
\end{figure*}

The conversion of a matrix to an \gls{add} is similar to that of a vector, but with an additional layer of nodes to represent the rows.
The \gls{add} can however be reduced as shown in \autoref{fig:add_reduced}.
This reduction is done by removing the duplicated terminal nodes, removing the redundant nodes and merging the nodes with the same children.
The techniques for reducing \glspl{add} is the standard reduction techniques used for \glspl{bdd}.
The reduction of the \gls{add} is done to reduce the size of the \gls{add} and to make the operations on the \gls{add} more efficient.
CUDD has built-in functions for reducing the \gls{add}, that follows the standard reduction techniques.

\begin{figure}
    \centering
    \input{figures/vector_add_example_reduced}
    \caption{Reduced ADD of matrix V}
    \label{fig:add_reduced}
\end{figure}

\subsection{Matrix operations using ADDs}\label{subsec:matrix-operations-using-adds}
The matrix operations are implemented using \glspl{add}.
The matrix operations implemented are matrix transpose, matrix addition, matrix multiplication, Hadamard product, Hadamard division, Kronecker product and Khatri-Rao product.

\[
    A = \begin{bmatrix}
            1 & 2 \\
            3 & 4 \\
    \end{bmatrix}
\]

and

\[
    B = \begin{bmatrix}
            5 & 6 \\
            7 & 8 \\
    \end{bmatrix}
\]

are used as examples in the following sections.

Their \glspl{add} representations are shown in \autoref{fig:add_matrix_a} and \autoref{fig:add_matrix_b} respectively.

\begin{figure}
    \centering
    \begin{tikzpicture}[
        level 1/.style={sibling distance=20mm},
        level 2/.style={sibling distance=10mm},
        level 3/.style={sibling distance=10mm}
    ]
        \node[c] {$x_1$}
        child{ node[c]  {$y_1$} edge from parent[zeroarrow]
        child{ node[t] {1}
        }
        child{ node [t] {2} edge from parent[onearrow]
        }
        }
        child{ node[c] {$y_1$} edge from parent[onearrow]
        child{ node[t] {3} edge from parent[zeroarrow]
        }
        child{ node[t] {4} edge from parent[onearrow]}
        }
        ;
    \end{tikzpicture}
    \caption{Matrix A in ADD}
    \label{fig:add_matrix_a}
\end{figure}

\begin{figure}
    \centering
    \begin{tikzpicture}[
        level 1/.style={sibling distance=20mm},
        level 2/.style={sibling distance=10mm},
        level 3/.style={sibling distance=10mm}
    ]
        \node[c] {$x_1$}
        child{ node[c]  {$y_1$} edge from parent[zeroarrow]
        child{ node[t] {5}
        }
        child{ node [t] {6} edge from parent[onearrow]
        }
        }
        child{ node[c] {$y_1$} edge from parent[onearrow]
        child{ node[t] {7} edge from parent[zeroarrow]
        }
        child{ node[t] {8} edge from parent[onearrow]}
        }
        ;
    \end{tikzpicture}
    \caption{Matrix B in ADD}
    \label{fig:add_matrix_b}
\end{figure}

\subsubsection{Matrix Transpose}
The matrix transpose is implemented by swapping the nodes in the \gls{add}, so that the rows become columns and the columns become rows.
The transpose of matrix $A$ is
\[
    A^T = \begin{bmatrix}
              1 & 3 \\
              2 & 4 \\
    \end{bmatrix}
\]

The \gls{add} representation of the transpose is shown in \autoref{fig:add_transpose}.
\begin{figure}
    \centering
    \input{figures/add_example_transpose}
    \caption{Matrix A Transposed}
    \label{fig:add_transpose}
\end{figure}

\subsubsection{Matrix addition}
Matrix addition is implemented by adding the \glspl{add} terminal nodes together.
The sum of matrices $A$ and $B$ is
\[
    A + B = \begin{bmatrix}
                1 & 2 \\
                3 & 4 \\
    \end{bmatrix} + \begin{bmatrix}
                        5 & 6 \\
                        7 & 8 \\
    \end{bmatrix} = \begin{bmatrix}
                        6  & 8  \\
                        10 & 12 \\
    \end{bmatrix}
\]

The \gls{add} representation of the sum is shown in \autoref{fig:add_addition}.
\begin{figure}
    \centering
    \input{figures/add_example_sum}
    \caption{Sum of matrices A and B}
    \label{fig:add_addition}
\end{figure}

\subsubsection{Matrix multiplication}
Matrix multiplication is implemented by performing the dot product of the rows and columns of the matrices.
The product of matrices $A$ and $B$ is

\[
    A \times B = \begin{bmatrix}
                     1 & 2 \\
                     3 & 4 \\
    \end{bmatrix} \times \begin{bmatrix}
                             5 & 6 \\
                             7 & 8 \\
    \end{bmatrix} = \begin{bmatrix}
                        19 & 22 \\
                        43 & 50 \\
    \end{bmatrix}
\]

The \gls{add} representation of the product can be seen in \autoref{fig:add_multiplication}.
\begin{figure}
    \centering
    \input{figures/add_example_muliplication}
    \caption{Product of matrices A and B}
    \label{fig:add_multiplication}
\end{figure}

\subsubsection{Hadamard product}
The Hadamard product is implemented by multiplying the corresponding elements of the matrices together.
The Hadamard product of matrices $A$ and $B$ is

\[
    A \circ B = \begin{bmatrix}
                    1 & 2 \\
                    3 & 4 \\
    \end{bmatrix} \circ \begin{bmatrix}
                            5 & 6 \\
                            7 & 8 \\
    \end{bmatrix} = \begin{bmatrix}
                        5  & 12 \\
                        21 & 32 \\
    \end{bmatrix}
\]

The \gls{add} representation of the Hadamard product is shown in \autoref{fig:add_hadamard}.

\begin{figure}
    \centering
    \input{figures/add_example_hadamard}
    \caption{Hadamard product of matrices A and B}
    \label{fig:add_hadamard}
\end{figure}

\subsubsection{Hadamard division}
The Hadamard division is implemented by dividing the corresponding elements of the matrices.
The Hadamard division of matrices $A$ and $B$ is

\[
    A \oslash B = \begin{bmatrix}
                      1 & 2 \\
                      3 & 4 \\
    \end{bmatrix} \oslash \begin{bmatrix}
                              5 & 6 \\
                              7 & 8 \\
    \end{bmatrix} = \begin{bmatrix}
                        0.2    & 0.3333 \\
                        0.4286 & 0.5    \\
    \end{bmatrix}
\]

The \gls{add} representation of the Hadamard division is shown in \autoref{fig:add_hadamard_division}.

\begin{figure}
    \centering
    \input{figures/add_example_hadamard_div}
    \caption{Hadamard division of matrices A and B}
    \label{fig:add_hadamard_division}
\end{figure}

\subsubsection{Kronecker product}
The Kronecker product is implemented by multiplying each element of the first matrix by the second matrix.
The Kronecker product of matrices $A$ and $B$ is

\[
    A \otimes B = \begin{bmatrix}
                      1 & 2 \\
                      3 & 4 \\
    \end{bmatrix} \otimes \begin{bmatrix}
                              5 & 6 \\
                              7 & 8 \\
    \end{bmatrix} = \begin{bmatrix}
                        5  & 6  & 10 & 12 \\
                        7  & 8  & 14 & 16 \\
                        15 & 18 & 20 & 24 \\
                        21 & 24 & 28 & 32 \\
    \end{bmatrix}
\]

The \gls{add} representation of the Kronecker product is shown in \autoref{fig:add_kroncker}.

\begin{figure*}
    \centering
    \input{figures/add_example_kroneker}
    \caption{Kronecker product of matrices A and B}
    \label{fig:add_kroncker}
\end{figure*}

\subsubsection{Khatri-Rao product}
The Khatri-Rao product is implemented by multiplying one element of the first matrix by the row of the second matrix.
The Khatri-Rao product of matrices $A$ and $B$ is

\[
    A \bullet B = \begin{bmatrix}
                      1 & 2 \\
                      3 & 4 \\
    \end{bmatrix} \bullet \begin{bmatrix}
                              5 & 6 \\
                              7 & 8 \\
    \end{bmatrix} = \begin{bmatrix}
                        5  & 6  & 10 & 12 \\
                        21 & 24 & 28 & 32 \\
    \end{bmatrix}
\]

The \gls{add} representation of the Khatri-Rao product is shown in \autoref{fig:add_katri_rao}.
\begin{figure*}
    \centering
    \input{figures/add_example_katri_rao}
    \caption{Khatri-Rao in ADD}
    \label{fig:add_katri_rao}
\end{figure*}

% \subsubsection{Matrix scalar}
% Matrix scalar is implemented by multiplying each element in the matrix by a scalar value.
% The scaling of matrix $A$ by a factor of 2 is
% \[
% 2 \times A = 2 \times \begin{bmatrix}
%     1 & 2 \\
%     3 & 4 \\
% \end{bmatrix} = \begin{bmatrix}
%     2 & 4 \\
%     6 & 8 \\
% \end{bmatrix}
% \]

% The \gls{add} representation of the scaled matrix is shown in Figure \ref{fig:add_scaling}.
% \begin{figure}
%     \centering
%     \begin{tikzpicture}[
% level 1/.style={sibling distance=20mm},
% level 2/.style={sibling distance=10mm},
% level 3/.style={sibling distance=10mm}
% ]
% \node[c] {$x_1$}
%     child{ node[c]  {$y_1$} edge from parent[zeroarrow]
%             child{ node[t] {2} 
%             }
%             child{ node [t] {4} edge from parent[onearrow]
%             }
%     }
%     child{ node[c] {$y_1$} edge from parent[onearrow]
%         child{ node[t] {6} edge from parent[zeroarrow]
%         }
%         child{ node[t] {8} edge from parent[onearrow]}
%     }
% ;
%     \end{tikzpicture}
%     \caption{Scaling of matrix A by a factor of 2}
%     \label{fig:add_scaling}
% \end{figure}
